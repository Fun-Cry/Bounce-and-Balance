# Reinforcement Learning for Jumping

__Maryia Zhyrko s4093771 and Po-Kai Chen s4283341__

This project focuses on training a one-legged "Rex" hopper robot to jump using Reinforcement Learning (RL) with Stable Baselines3 and the CoppeliaSim robotics simulator. The aim is to develop an agent capable of stable and effective jumping maneuvers.

## Project Overview

The core of this project involves a custom Gymnasium environment that interfaces with a CoppeliaSim simulation of the Rex hopper. Reinforcement learning agents, primarily using Proximal Policy Optimization (PPO) from Stable Baselines3, are trained to control the robot's actuators. The project includes functionalities for different training modes (e.g., `joints_only`), hyperparameter optimization, and detailed asset management for the robot model.

## Folder Structure

* **`/` (Root Directory)**
    * `README.md`: This file.
    * `env_runner.py`: Main script for configuring environments, training RL agents, and loading models.
    * `train.py`: Potentially an alternative script for running specific environment sessions or tests.
    * `hpo.py`: Script for Hyperparameter Optimization of the RL models.
    * `requirements.txt`: Lists the Python dependencies for the project.
    * Various `.zip` files (e.g., `sb3_rex_model*.zip`, `jumps_sometimes.zip`, `actuator.zip`): These are various saved model checkpoints from different stages of training and experimentation.
* **`/assets`**: Contains 3D model assets for the robot.
    * `hopper_rev08/meshes/*.STL`: Mesh files for the robot parts.
    * `hopper_rev08/urdf/*.urdf, *.csv`: URDF (Unified Robot Description Format) files and associated CSVs for the robot model.
* **`/env`**: Core Python package defining the reinforcement learning environment.
    * `mountain_env.py`: The custom Gymnasium environment (`CoppeliaMountainEnv`) defining observation/action spaces, step logic, and the crucial reward function.
    * `simulation_copp.py`: Handles the ZMQ communication interface with CoppeliaSim, robot control commands, physics stepping, and sensor data retrieval.
    * `actuator.py` & `actuator_param.py`: Define the actuator models and their specific parameters.
    * `robot_model.py`: Contains parameters and configurations for the robot model itself.
    * `scene_elements.py`: Utility for procedurally generating dynamic elements (like 'mountains') within the CoppeliaSim scene.
    * `utils.py`: Utility functions specifically for the environment and simulation.
* **`/sb3_rex_model_joints_only_checkpoints`**: Automatically stores checkpoints generated by Stable Baselines3 during training runs in the `joints_only` mode.
* **`/scenes`**: Contains CoppeliaSim scene files (`.ttt`).
    * `rex_camera.ttt`: Scene configured with a camera sensor.
    * `rex_lidar.ttt`: Scene configured with a LiDAR sensor.
* **`/test`**: Contains scripts for testing and debugging.
    * `debug_sim.py`: For testing and debugging the CoppeliaSim connection and basic simulation interaction.
    * `joint_test.py`: For testing individual or groups of robot joints.
* **`/utils`**: Root-level utility scripts.
    * `coppelia_launcher.py`: Script to help automate the launching and closing of CoppeliaSim instances.

## Prerequisites

* **Python** (e.g., 3.9 as indicated by `.pyc` files, but likely 3.8+ is fine).
* **CoppeliaSim Education Version** (e.g., V4.5.x or V4.6.x). The ZMQ Remote API server must be enabled (e.g., `simRemoteApi.start(19997)` in a scene script).
* **Python Libraries**: Listed in `requirements.txt`. Key dependencies include:
    * `gymnasium`
    * `stable-baselines3[extra]`
    * `numpy`
    * `opencv-python`
    * `coppeliasim-zmqremoteapi-client`

## Setup

1.  **Clone the repository.**
2.  **Install Python dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Set up CoppeliaSim:**
    * Download and install CoppeliaSim.
    * Ensure the ZMQ Remote API is properly configured and accessible.
    * The project's scene files are in the `/scenes` directory.

## Running the Project

### 1. Start CoppeliaSim

* You can try using `python utils/coppelia_launcher.py` if configured.
* Alternatively, manually open CoppeliaSim.
* Load the desired scene (e.g., `scenes/rex_camera.ttt`).
* Ensure the simulation is ready to be controlled via the remote API (usually, the simulation should be **stopped** in the GUI, as the Python scripts will start/step it).
* Verify the ZMQ server is active within the CoppeliaSim scene.

### 2. Training an Agent

The primary script for training is `env_runner.py`.

* **Configuration in `env_runner.py`:**
    * `CURRENT_MODE`: Set to `'joints_only'` or `'normal'`.
    * `USE_CAMERA`: Set to `True` or `False`.
    * `total_timesteps_target`: Adjust in the main execution block to define the overall length of the training run.
    * `checkpoint_step_to_load`: Set inside the `train_with_stable_baselines3` function to load a specific checkpoint (e.g., `1000000`). The script looks for `ppo_rex_{checkpoint_step_to_load}_steps.zip`.
* **Run:**
    ```bash
    python env_runner.py
    ```
* Trained models and checkpoints are saved in folders like `/sb3_rex_model_joints_only_checkpoints` and as final models like `sb3_rex_model_joints_only.zip` in the root directory.

### 3. Hyperparameter Optimization

* Run the `hpo.py` script to perform hyperparameter searches (details of its usage would be within that script or require further documentation).

### 4. Modifying Environment & Rewards

* The core logic for agent-environment interaction, including the **reward shaping**, is in `env/mountain_env.py` (`CoppeliaMountainEnv` class).
* Low-level simulation control and action processing (like reaction wheel scaling) is in `env/simulation_copp.py`.
* Actuator characteristics are in `env/actuator.py` and `env/actuator_param.py`.

### 5. Testing

* Use scripts in the `/test` directory (e.g., `debug_sim.py`, `joint_test.py`) for specific tests.
* The `env_runner.py` also has a section for testing the trained agent after the learning phase. Set `render_mode="human"` for visualization.

## Key Files

* `env_runner.py`: Main training and execution script.
* `env/mountain_env.py`: Gym environment definition (CRITICAL for RL behavior).
* `env/simulation_copp.py`: CoppeliaSim communication and control logic.
* `scenes/rex_camera.ttt`: Primary CoppeliaSim scene for camera-based or `joints_only` modes.
* `requirements.txt`: Python dependencies.
* `hpo.py`: For hyperparameter optimization.

## Notes

* The project has seen significant iteration on reward functions to achieve stable jumping.
* The `joints_only` mode, combined with specific reaction wheel action scaling in `simulation_copp.py`, has shown the most promise for stable learning.
* Always ensure CoppeliaSim is running and correctly configured before launching Python training scripts.

